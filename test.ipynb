{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90d12e71-ba1b-4293-9b40-6f5c296bdca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "# Our custom module\n",
    "from nn import DeepQNetwork\n",
    "from custom_parking_env import ParkingWithObstacles\n",
    "\n",
    "# python module\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# if GPU is to be used\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "    \n",
    "policy_net_weights = torch.load('policy_net.pth', weights_only=False)\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8931ec42-dc25-470a-8724-5cc88e5f3f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_actions = []\n",
    "\n",
    "for steering in np.linspace(-0.5, 0.5, 3):\n",
    "        for acceleration in np.linspace(0.8, 0.4, 2):\n",
    "            candidate_actions.append(torch.Tensor([acceleration, steering]))\n",
    "            \n",
    "# print(candidate_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51c0f35f-d5cd-4c39-a397-5c5c64b10626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'observation': {'type': 'KinematicsGoal', 'features': ['x', 'y', 'vx', 'vy', 'cos_h', 'sin_h'], 'scales': [100, 100, 5, 5, 1, 1], 'normalize': True}, 'action': {'type': 'ContinuousAction'}, 'simulation_frequency': 15, 'policy_frequency': 5, 'other_vehicles_type': 'highway_env.vehicle.behavior.IDMVehicle', 'screen_width': 1200, 'screen_height': 600, 'centering_position': [0.5, 0.5], 'scaling': 9, 'show_trajectories': False, 'render_agent': True, 'offscreen_rendering': False, 'manual_control': False, 'real_time_rendering': False, 'reward_weights': [1, 1, 0, 0, 0, 0], 'success_goal_reward': 0.12, 'collision_reward': -5, 'steering_range': 0.7853981633974483, 'duration': 30, 'controlled_vehicles': 1, 'vehicles_count': 0, 'add_walls': False, 'add_obstacles': True, 'obstacles_count': 0}\n",
      "Dict('achieved_goal': Box(-inf, inf, (6,), float64), 'desired_goal': Box(-inf, inf, (6,), float64), 'observation': Box(-inf, inf, (6,), float64))\n"
     ]
    }
   ],
   "source": [
    "# combine observation\n",
    "def process_observation(observation):\n",
    "    # observation_vector = np.concatenate((\n",
    "    #     observation[\"observation\"],\n",
    "    #     observation[\"achieved_goal\"],\n",
    "    #     observation[\"desired_goal\"]\n",
    "    # ))\n",
    "    return observation[\"observation\"]\n",
    "\n",
    "# Create the original environment and wrap it into an environment with obstacles\n",
    "env_origin = gym.make(\"parking-v0\", render_mode=\"human\")\n",
    "env = ParkingWithObstacles(env_origin)\n",
    "env.define_spaces()\n",
    "\n",
    "print(env.config)\n",
    "\n",
    "# Get the number of state observations\n",
    "state, info = env.reset()\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = len(candidate_actions)\n",
    "n_observations = len(process_observation(state))  # 6 (observation) \n",
    "\n",
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16a2c838-f64f-4315-8d4c-5b4e6b76e6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DeepQNetwork(n_observations,n_actions).to(device)\n",
    "# Testing\n",
    "# Load the model weights\n",
    "model.load_state_dict(policy_net_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59313ff3-782c-4ee9-903d-0b98406c94c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo Episode 1 started...\n",
      "0\n",
      "0.2\n",
      "0.4\n",
      "0.6000000000000001\n",
      "0.8\n",
      "1.0\n",
      "1.2\n",
      "1.4\n",
      "1.5999999999999999\n",
      "1.7999999999999998\n",
      "1.9999999999999998\n",
      "2.1999999999999997\n",
      "2.4\n",
      "2.6\n",
      "2.8000000000000003\n",
      "3.0000000000000004\n",
      "3.2000000000000006\n",
      "3.400000000000001\n",
      "3.600000000000001\n",
      "3.800000000000001\n",
      "4.000000000000001\n",
      "4.200000000000001\n",
      "4.400000000000001\n",
      "4.600000000000001\n",
      "4.800000000000002\n",
      "5.000000000000002\n",
      "5.200000000000002\n",
      "5.400000000000002\n",
      "5.600000000000002\n",
      "5.8000000000000025\n",
      "6.000000000000003\n",
      "6.200000000000003\n",
      "6.400000000000003\n",
      "6.600000000000003\n",
      "6.800000000000003\n",
      "7.0000000000000036\n",
      "7.200000000000004\n",
      "7.400000000000004\n",
      "7.600000000000004\n",
      "7.800000000000004\n",
      "8.000000000000004\n",
      "8.200000000000003\n",
      "8.400000000000002\n",
      "8.600000000000001\n",
      "8.8\n",
      "9.0\n",
      "9.2\n",
      "9.399999999999999\n",
      "9.599999999999998\n",
      "9.799999999999997\n",
      "9.999999999999996\n",
      "10.199999999999996\n",
      "10.399999999999995\n",
      "10.599999999999994\n",
      "10.799999999999994\n",
      "10.999999999999993\n",
      "11.199999999999992\n",
      "11.399999999999991\n",
      "11.59999999999999\n",
      "11.79999999999999\n",
      "11.99999999999999\n",
      "12.199999999999989\n",
      "12.399999999999988\n",
      "12.599999999999987\n",
      "12.799999999999986\n",
      "12.999999999999986\n",
      "13.199999999999985\n",
      "13.399999999999984\n",
      "13.599999999999984\n",
      "13.799999999999983\n",
      "13.999999999999982\n",
      "14.199999999999982\n",
      "14.39999999999998\n",
      "14.59999999999998\n",
      "14.79999999999998\n",
      "14.999999999999979\n",
      "15.199999999999978\n",
      "15.399999999999977\n",
      "15.599999999999977\n",
      "15.799999999999976\n",
      "15.999999999999975\n",
      "16.199999999999974\n",
      "16.399999999999974\n",
      "16.599999999999973\n",
      "16.799999999999972\n",
      "16.99999999999997\n",
      "17.19999999999997\n",
      "17.39999999999997\n",
      "17.59999999999997\n",
      "17.79999999999997\n",
      "17.999999999999968\n",
      "18.199999999999967\n",
      "18.399999999999967\n",
      "18.599999999999966\n",
      "18.799999999999965\n",
      "18.999999999999964\n",
      "19.199999999999964\n",
      "19.399999999999963\n",
      "19.599999999999962\n",
      "19.79999999999996\n",
      "19.99999999999996\n",
      "20.19999999999996\n",
      "20.39999999999996\n",
      "20.59999999999996\n",
      "20.799999999999958\n",
      "20.999999999999957\n",
      "21.199999999999957\n",
      "21.399999999999956\n",
      "21.599999999999955\n",
      "21.799999999999955\n",
      "21.999999999999954\n",
      "22.199999999999953\n",
      "22.399999999999952\n",
      "22.59999999999995\n",
      "22.79999999999995\n",
      "22.99999999999995\n",
      "23.19999999999995\n",
      "23.39999999999995\n",
      "23.599999999999948\n",
      "23.799999999999947\n",
      "23.999999999999947\n",
      "24.199999999999946\n",
      "24.399999999999945\n",
      "24.599999999999945\n",
      "24.799999999999944\n",
      "24.999999999999943\n",
      "25.199999999999942\n",
      "25.39999999999994\n",
      "25.59999999999994\n",
      "25.79999999999994\n",
      "25.99999999999994\n",
      "26.19999999999994\n",
      "26.399999999999938\n",
      "26.599999999999937\n",
      "26.799999999999937\n",
      "26.999999999999936\n",
      "27.199999999999935\n",
      "27.399999999999935\n",
      "27.599999999999934\n",
      "27.799999999999933\n",
      "27.999999999999932\n",
      "28.199999999999932\n",
      "28.39999999999993\n",
      "28.59999999999993\n",
      "28.79999999999993\n",
      "28.99999999999993\n",
      "29.19999999999993\n",
      "29.399999999999928\n",
      "29.599999999999927\n",
      "29.799999999999926\n",
      "29.999999999999925\n",
      "False\n",
      "True\n",
      "{'speed': 40.00000000000005, 'crashed': False, 'action': array([ 0.8, -0.5], dtype=float32), 'is_success': False}\n",
      "Episode 1 ended. Total Reward: -101.99455208229105\n",
      "Progress: 1/1\n",
      "Test completed over 1 episodes.\n",
      "Average reward: -101.99, Average duration: 151.00 steps.\n",
      "Max reward: -101.99, Min reward: -101.99\n"
     ]
    }
   ],
   "source": [
    "def test(env, model, num_episodes=100):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_test_rewards = []\n",
    "    episode_durations = []\n",
    "    \n",
    "    def to_tensor(vector):\n",
    "        return torch.tensor(vector, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "    for i_episode in range(num_episodes):\n",
    "        observation, info = env.reset()\n",
    "        observation_tensor = to_tensor(process_observation(observation))\n",
    "        \n",
    "        total_reward = 0\n",
    "        index = 0\n",
    "        print(f\"Demo Episode {i_episode + 1} started...\")\n",
    "\n",
    "        while True:\n",
    "            print(env.time)\n",
    "            with torch.no_grad():\n",
    "                action_index = model(observation_tensor).max(1)[1].view(1, 1)\n",
    "\n",
    "            try:\n",
    "                action = candidate_actions[action_index.item()]\n",
    "            except IndexError:\n",
    "                print(f\"Invalid action index: {action_index.item()}\")\n",
    "                break\n",
    "\n",
    "            observation, reward, done, truncated, info = env.step(action.numpy())\n",
    "            total_reward += reward\n",
    "\n",
    "            if done or truncated:\n",
    "                print(f\"Done: {done}, Truncated: {truncated}\")\n",
    "                print(info)\n",
    "                print(f\"Episode {i_episode + 1} ended. Total Reward: {total_reward}\")\n",
    "                break\n",
    "\n",
    "            observation_tensor = to_tensor(process_observation(observation))\n",
    "            index += 1\n",
    "\n",
    "        episode_durations.append(index + 1)\n",
    "        total_test_rewards.append(total_reward)\n",
    "        print(f\"Progress: {i_episode + 1}/{num_episodes}\")\n",
    "\n",
    "    env.close()\n",
    "    avg_reward = np.mean(total_test_rewards)\n",
    "    avg_duration = np.mean(episode_durations)\n",
    "    print(f\"Test completed over {num_episodes} episodes.\")\n",
    "    print(f\"Average reward: {avg_reward:.2f}, Average duration: {avg_duration:.2f} steps.\")\n",
    "    print(f\"Max reward: {np.max(total_test_rewards):.2f}, Min reward: {np.min(total_test_rewards):.2f}\")\n",
    "\n",
    "\n",
    "test(env, model, num_episodes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "917441fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5963da6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
