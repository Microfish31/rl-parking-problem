{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "90d12e71-ba1b-4293-9b40-6f5c296bdca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "# Our custom module\n",
    "from nn import DeepQNetwork\n",
    "from custom_parking_env import ParkingWithObstacles\n",
    "\n",
    "# python module\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# if GPU is to be used\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "    \n",
    "policy_net_weights = torch.load('policy_net.pth', weights_only=False)\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8931ec42-dc25-470a-8724-5cc88e5f3f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_actions = []\n",
    "\n",
    "for steering in np.linspace(-0.5, 0.5, 11):\n",
    "        for acceleration in np.linspace(0.8, 0.4, 4):\n",
    "            candidate_actions.append(torch.Tensor([acceleration, steering]))\n",
    "            \n",
    "# print(candidate_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "51c0f35f-d5cd-4c39-a397-5c5c64b10626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'observation': {'type': 'KinematicsGoal', 'features': ['x', 'y', 'vx', 'vy', 'cos_h', 'sin_h'], 'scales': [100, 100, 5, 5, 1, 1], 'normalize': True}, 'action': {'type': 'ContinuousAction'}, 'simulation_frequency': 15, 'policy_frequency': 5, 'other_vehicles_type': 'highway_env.vehicle.behavior.IDMVehicle', 'screen_width': 1200, 'screen_height': 600, 'centering_position': [0.5, 0.5], 'scaling': 9, 'show_trajectories': False, 'render_agent': True, 'offscreen_rendering': False, 'manual_control': False, 'real_time_rendering': False, 'reward_weights': [0.5, 0.5, 0, 0, 0.02, 0.02], 'success_goal_reward': 0.15, 'collision_reward': -5, 'steering_range': 0.7853981633974483, 'duration': 50, 'controlled_vehicles': 1, 'vehicles_count': 0, 'add_walls': False, 'add_obstacles': True, 'obstacles_count': 3}\n",
      "Dict('achieved_goal': Box(-inf, inf, (6,), float64), 'desired_goal': Box(-inf, inf, (6,), float64), 'observation': Box(-inf, inf, (6,), float64))\n"
     ]
    }
   ],
   "source": [
    "# combine observation\n",
    "def process_observation(observation):\n",
    "    # observation_vector = np.concatenate((\n",
    "    #     observation[\"observation\"],\n",
    "    #     observation[\"achieved_goal\"],\n",
    "    #     observation[\"desired_goal\"]\n",
    "    # ))\n",
    "    return observation[\"observation\"]\n",
    "\n",
    "# Create the original environment and wrap it into an environment with obstacles\n",
    "env_origin = gym.make(\"parking-v0\", render_mode=\"human\")\n",
    "env = ParkingWithObstacles(env_origin)\n",
    "env.define_spaces()\n",
    "\n",
    "print(env.config)\n",
    "\n",
    "# Get the number of state observations\n",
    "state, info = env.reset()\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = len(candidate_actions)\n",
    "n_observations = len(process_observation(state))  # 6 (observation) \n",
    "\n",
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "16a2c838-f64f-4315-8d4c-5b4e6b76e6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DeepQNetwork(n_observations,n_actions).to(device)\n",
    "# Testing\n",
    "# Load the model weights\n",
    "model.load_state_dict(policy_net_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "59313ff3-782c-4ee9-903d-0b98406c94c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo Episode 1 started...\n",
      "Done: True, Truncated: False\n",
      "{'speed': 22.666667342185956, 'crashed': True, 'action': array([ 0.6666667, -0.5      ], dtype=float32), 'is_success': False}\n",
      "Episode 1 ended. Total Reward: -22.068151634551086\n",
      "Progress: 1/10\n",
      "Demo Episode 2 started...\n",
      "Done: True, Truncated: False\n",
      "{'speed': 6.581728591212516, 'crashed': True, 'action': array([ 0.6666667, -0.5      ], dtype=float32), 'is_success': False}\n",
      "Episode 2 ended. Total Reward: -9.851301345913953\n",
      "Progress: 2/10\n",
      "Demo Episode 3 started...\n",
      "Done: True, Truncated: False\n",
      "{'speed': 20.32592653168571, 'crashed': True, 'action': array([ 0.6666667, -0.5      ], dtype=float32), 'is_success': False}\n",
      "Episode 3 ended. Total Reward: -17.31671001588114\n",
      "Progress: 3/10\n",
      "Demo Episode 4 started...\n",
      "Done: True, Truncated: False\n",
      "{'speed': 6.000987833164354, 'crashed': True, 'action': array([ 0.6666667, -0.5      ], dtype=float32), 'is_success': False}\n",
      "Episode 4 ended. Total Reward: -8.769365967975284\n",
      "Progress: 4/10\n",
      "Demo Episode 5 started...\n",
      "Done: True, Truncated: False\n",
      "{'speed': 6.000987833164354, 'crashed': True, 'action': array([0.6666667, 0.2      ], dtype=float32), 'is_success': False}\n",
      "Episode 5 ended. Total Reward: -10.493045526147974\n",
      "Progress: 5/10\n",
      "Demo Episode 6 started...\n",
      "Done: True, Truncated: False\n",
      "{'speed': 6.000987833164354, 'crashed': True, 'action': array([0.6666667, 0.2      ], dtype=float32), 'is_success': False}\n",
      "Episode 6 ended. Total Reward: -9.910652662562669\n",
      "Progress: 6/10\n",
      "Demo Episode 7 started...\n",
      "Done: True, Truncated: False\n",
      "{'speed': 22.00000065565108, 'crashed': True, 'action': array([ 0.6666667, -0.5      ], dtype=float32), 'is_success': False}\n",
      "Episode 7 ended. Total Reward: -20.568944186000905\n",
      "Progress: 7/10\n",
      "Demo Episode 8 started...\n",
      "Done: True, Truncated: False\n",
      "{'speed': 3.028148282898797, 'crashed': True, 'action': array([ 0.6666667, -0.2      ], dtype=float32), 'is_success': False}\n",
      "Episode 8 ended. Total Reward: -7.577081962198214\n",
      "Progress: 8/10\n",
      "Demo Episode 9 started...\n",
      "Done: True, Truncated: False\n",
      "{'speed': 34.84444444809334, 'crashed': True, 'action': array([0.8, 0.4], dtype=float32), 'is_success': False}\n",
      "Episode 9 ended. Total Reward: -40.14828118352679\n",
      "Progress: 9/10\n",
      "Demo Episode 10 started...\n",
      "Done: True, Truncated: False\n",
      "{'speed': 6.637037234836152, 'crashed': True, 'action': array([ 0.6666667, -0.5      ], dtype=float32), 'is_success': False}\n",
      "Episode 10 ended. Total Reward: -9.170000953359263\n",
      "Progress: 10/10\n",
      "Test completed over 10 episodes.\n",
      "Average reward: -15.59, Average duration: 24.00 steps.\n",
      "Max reward: -7.58, Min reward: -40.15\n"
     ]
    }
   ],
   "source": [
    "def test(env, model, num_episodes=100):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_test_rewards = []\n",
    "    episode_durations = []\n",
    "    \n",
    "    def to_tensor(vector):\n",
    "        return torch.tensor(vector, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "    for i_episode in range(num_episodes):\n",
    "        observation, info = env.reset()\n",
    "        observation_tensor = to_tensor(process_observation(observation))\n",
    "        \n",
    "        total_reward = 0\n",
    "        index = 0\n",
    "        print(f\"Demo Episode {i_episode + 1} started...\")\n",
    "\n",
    "        while True:\n",
    "            # print(env.time)\n",
    "            with torch.no_grad():\n",
    "                action_index = model(observation_tensor).max(1)[1].view(1, 1)\n",
    "\n",
    "            try:\n",
    "                action = candidate_actions[action_index.item()]\n",
    "            except IndexError:\n",
    "                print(f\"Invalid action index: {action_index.item()}\")\n",
    "                break\n",
    "\n",
    "            observation, reward, done, truncated, info = env.step(action.numpy())\n",
    "            total_reward += reward\n",
    "\n",
    "            if done or truncated:\n",
    "                print(f\"Done: {done}, Truncated: {truncated}\")\n",
    "                print(info)\n",
    "                print(f\"Episode {i_episode + 1} ended. Total Reward: {total_reward}\")\n",
    "                break\n",
    "\n",
    "            observation_tensor = to_tensor(process_observation(observation))\n",
    "            index += 1\n",
    "\n",
    "        episode_durations.append(index + 1)\n",
    "        total_test_rewards.append(total_reward)\n",
    "        print(f\"Progress: {i_episode + 1}/{num_episodes}\")\n",
    "\n",
    "    env.close()\n",
    "    avg_reward = np.mean(total_test_rewards)\n",
    "    avg_duration = np.mean(episode_durations)\n",
    "    print(f\"Test completed over {num_episodes} episodes.\")\n",
    "    print(f\"Average reward: {avg_reward:.2f}, Average duration: {avg_duration:.2f} steps.\")\n",
    "    print(f\"Max reward: {np.max(total_test_rewards):.2f}, Min reward: {np.min(total_test_rewards):.2f}\")\n",
    "\n",
    "\n",
    "test(env, model, num_episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "917441fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
